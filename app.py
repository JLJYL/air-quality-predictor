# app.py - Open-Meteo Weather Integration Revision (with Traceback Debugging)

# =================================================================
# Import all necessary libraries 
# =================================================================
import requests
import pandas as pd
import datetime
import random
import re
import os
import warnings
import numpy as np
import xgboost as xgb
import json
import traceback # <-- Added for debugging
from datetime import timedelta, timezone
from flask import Flask, render_template, request
# å¼•å…¥ Open-Meteo ç›¸é—œå‡½å¼åº«
import openmeteo_requests
import requests_cache
from retry import retry

# Ignore warnings
warnings.filterwarnings('ignore')

# Model and metadata paths
MODELS_DIR = 'models'
META_PATH = os.path.join(MODELS_DIR, 'model_meta.json')

# =================================================================
# OpenAQ API Constants
# =================================================================
# âš ï¸ Replace with your own API Key
API_KEY = "fb579916623e8483cd85344b14605c3109eea922202314c44b87a2df3b1fff77" 
HEADERS = {"X-API-Key": API_KEY}
# BASE V3
BASE = "https://api.openaq.org/v3"

# Target geographical coordinates (Default for initial load)
TARGET_LAT = 22.6324 
TARGET_LON = 120.2954

# Initial/Default Location (These will be updated by initialize_location)
DEFAULT_LOCATION_ID = 2395624 # Default: Kaohsiung-Qianjin
DEFAULT_LOCATION_NAME = "Kaohsiung-Qianjin"
DEFAULT_CITY = "Kaohsiung City"
DEFAULT_COUNTRY = "TW"

# Timezone setting for localization
LOCAL_TZ = "Asia/Taipei"

# Pollutants used for modeling
POLLUTANT_TARGETS = ["pm25", "pm10", "o3", "no2", "so2", "co"]
# Feature columns must match train_and_save.py
FEATURE_COLUMNS = [] # Will be loaded from model_meta.json

# Globals to store loaded model/data
TRAINED_MODELS = {}
LAST_OBSERVATION = None 
INITIAL_AQI_INFO = None
LOCATION_LIST = []

# Open-Meteo Setup
# Setup the cache for Open-Meteo requests
cache_session = requests_cache.CachedSession('.openmeteo_cache', expire_after = 3600)  # Cache for 1 hour
openmeteo = openmeteo_requests.Client(session=cache_session)
WEATHER_URL = "https://api.open-meteo.com/v1/forecast"


# =================================================================
# AQI Calculation (Referencing US EPA Standard)
# =================================================================
# AQI Breakpoints (Simplified for main pollutants)
AQI_BREAKPOINTS = {
    'pm25': [(0.0, 12.0, 0, 50), (12.1, 35.4, 51, 100), (35.5, 55.4, 101, 150), 
             (55.5, 150.4, 151, 200), (150.5, 250.4, 201, 300), (250.5, 500.4, 301, 500)],
    'pm10': [(0, 54, 0, 50), (55, 154, 51, 100), (155, 254, 101, 150), 
             (255, 354, 151, 200), (355, 424, 201, 300), (425, 604, 301, 500)],
    # O3, NO2, SO2, CO... (Simplified for core pollutants)
}

def aqi_from_conc(pollutant, conc):
    """è¨ˆç®—å–®ä¸€æ±¡æŸ“ç‰©æ¿ƒåº¦å°æ‡‰çš„ AQI"""
    if pd.isna(conc) or conc < 0:
        return np.nan
    
    # æŸ¥æ‰¾å°æ‡‰çš„æ±¡æŸ“ç‰©å€é–“
    breakpoints = AQI_BREAKPOINTS.get(pollutant, [])
    
    for bp_low, bp_high, aqi_low, aqi_high in breakpoints:
        if bp_low <= conc <= bp_high:
            # ä½¿ç”¨ç·šæ€§æ’å€¼å…¬å¼
            if bp_low == bp_high: # é¿å…é™¤ä»¥é›¶
                return aqi_low
            
            aqi = ((aqi_high - aqi_low) / (bp_high - bp_low)) * (conc - bp_low) + aqi_low
            return int(round(aqi))
    
    # è¶…å‡ºæœ€é«˜å€é–“
    if breakpoints and conc > breakpoints[-1][1]:
         # ç°¡å–®åœ°è¿”å›æœ€é«˜å€é–“çš„æœ€é«˜ AQI æˆ– NaN
        return np.nan # ä¿æŒä¸€è‡´æ€§ï¼Œå¦‚æœè¶…å‡ºï¼Œå‰‡è®“ max() å¿½ç•¥
        
    return np.nan

def calculate_aqi(row):
    """è¨ˆç®—è§€æ¸¬æ•¸æ“šçš„æ•´é«” AQI,å–æ‰€æœ‰æ±¡æŸ“ç‰© AQI çš„æœ€å¤§å€¼"""
    aqis = []
    
    for param in POLLUTANT_TARGETS:
        conc = row.get(f'{param}_value') # ä½¿ç”¨å¸¶æœ‰ _value çš„æ¬„ä½
        if pd.notna(conc):
            aqi = aqi_from_conc(param, conc)
            if pd.notna(aqi):
                aqis.append(aqi)
    
    # æ³¨æ„: é€™è£¡è¨ˆç®—çš„æ˜¯è§€æ¸¬æˆ–é æ¸¬å¾Œçš„ 'aqi' æ¬„ä½ï¼Œä¸æ‡‰è©²è®€å– 'aqi_pred'
    # 'aqi_pred' æ‡‰åªåœ¨ predict_future_multi ä¸­ç”¨æ–¼æœ€çµ‚è¼¸å‡ºã€‚
        
    if not aqis:
        return np.nan
        
    # æ•´é«” AQI ç‚ºæ‰€æœ‰æ±¡æŸ“ç‰© AQI ä¸­çš„æœ€å¤§å€¼
    return max(aqis)

def get_aqi_category(aqi):
    """æ ¹æ“š AQI å€¼è¿”å›é¡åˆ¥å’Œé¡è‰²"""
    if pd.isna(aqi) or aqi == "N/A": return "N/A", "gray"
    aqi = int(aqi)
    
    if 0 <= aqi <= 50:
        return "è‰¯å¥½", "bg-emerald-500"
    elif 51 <= aqi <= 100:
        return "ä¸­ç­‰", "bg-yellow-500"
    elif 101 <= aqi <= 150:
        return "å°æ•æ„Ÿæ—ç¾¤ä¸å¥åº·", "bg-orange-500"
    elif 151 <= aqi <= 200:
        return "ä¸å¥åº·", "bg-red-600"
    elif 201 <= aqi <= 300:
        return "éå¸¸ä¸å¥åº·", "bg-purple-600"
    else:
        return "å±éšª", "bg-gray-800"


# =================================================================
# OpenAQ Data Fetching Functions
# =================================================================

@retry(tries=3, delay=2, backoff=2, exceptions=(requests.exceptions.Timeout, requests.exceptions.HTTPError))
def fetch_location_list(country_id=DEFAULT_COUNTRY):
    """ç²å–åœ‹å®¶/åœ°å€å…§çš„æ¸¬ç«™åˆ—è¡¨"""
    try:
        url = f"{BASE}/locations"
        params = {
            'country_id': country_id,
            'limit': 1000,
            'order_by': 'name'
        }
        response = requests.get(url, headers=HEADERS, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        locations = []
        for loc in data.get('results', []):
            loc_id = loc.get('id')
            name = loc.get('name')
            # ç¢ºä¿æœ‰å¿…è¦çš„è³‡è¨Š
            if loc_id and name:
                 locations.append({
                    'id': loc_id,
                    'name': name,
                    'city': loc.get('city', 'N/A'),
                    'latitude': loc.get('coordinates', {}).get('latitude'),
                    'longitude': loc.get('coordinates', {}).get('longitude')
                 })
                 
        # åƒ…ä¿ç•™æœ‰ç¶“ç·¯åº¦çš„æ¸¬ç«™
        LOCATION_LIST.extend([loc for loc in locations if loc['latitude'] is not None and loc['longitude'] is not None])
        print(f"âœ… [Location] Loaded {len(LOCATION_LIST)} locations.")

    except Exception as e:
        print(f"âŒ [Location] Error fetching locations: {e}")
        traceback.print_exc()

@retry(tries=3, delay=2, backoff=2, exceptions=(requests.exceptions.Timeout, requests.exceptions.HTTPError))
def fetch_latest_observation(location_id):
    """ç²å–å–®ä¸€æ¸¬ç«™çš„æœ€æ–°è§€æ¸¬æ•¸æ“š"""
    try:
        url = f"{BASE}/latest"
        params = {
            'location_id': location_id,
            'limit': 100, # ç²å–æ‰€æœ‰æ±¡æŸ“ç‰©
            'parameter_id': [f"pm25", "pm10", "o3", "no2", "so2", "co"]
        }
        response = requests.get(url, headers=HEADERS, params=params, timeout=10)
        response.raise_for_status()
        data = response.json()
        
        # æª¢æŸ¥æ˜¯å¦æœ‰çµæœæˆ–æ¸¬é‡æ•¸æ“š
        if not data.get('results') or not data['results'][0].get('measurements'):
            print(f"âš ï¸ [OpenAQ] No measurements found for location ID: {location_id}.")
            return pd.DataFrame()

        # æ‰å¹³åŒ–çµæœ
        latest_data = data['results'][0]
        obs = latest_data['measurements']
        
        # è½‰æ›ç‚º DataFrame
        df = pd.DataFrame(obs)
        if df.empty:
            return pd.DataFrame()
            
        # è½‰æ›æ—¥æœŸæ™‚é–“ã€‚API è¿”å›çš„æ™‚é–“æ˜¯ UTCï¼Œä½†æ²’æœ‰æ™‚å€æ¨™è¨˜ï¼Œæˆ‘å€‘å‡è¨­å®ƒæ˜¯ä¸€å€‹ 'Z' çµå°¾çš„ UTC æ™‚é–“
        df['datetime'] = pd.to_datetime(df['datetime'])
        # å°‡ UTC æ™‚é–“è½‰æ›ç‚ºæœ¬åœ°æ™‚å€ï¼Œç„¶å¾Œç§»é™¤æ™‚å€è³‡è¨Š (Naive Local Time)
        df['datetime'] = df['datetime'].dt.tz_convert(LOCAL_TZ).dt.tz_localize(None)
        
        # è½‰æ›ç‚ºå¯¬æ ¼å¼
        pivot_df = df.pivot_table(index='datetime', columns='parameter_id', values='value').reset_index()
        
        # ç¢ºä¿æ‰€æœ‰ç›®æ¨™æ±¡æŸ“ç‰©æ¬„ä½å­˜åœ¨ (å¦‚æœ OpenAQ æ²’æœ‰è¿”å›ï¼Œå‰‡å¡« NaN)
        for param in POLLUTANT_TARGETS:
            if param not in pivot_df.columns:
                pivot_df[param] = np.nan
        
        # åƒ…ä¿ç•™æœ€æ–°ä¸€ç­†æ•¸æ“š
        latest_row = pivot_df.sort_values(by='datetime', ascending=False).iloc[:1].copy()
        
        # è¨ˆç®— AQI
        latest_row['aqi'] = latest_row.apply(
            lambda row: max([aqi_from_conc(p, row[p]) for p in POLLUTANT_TARGETS if p in row and pd.notna(row[p])]), 
            axis=1
        )
        
        # é‡æ–°å‘½åä»¥åŒ¹é…è¨“ç·´æ•¸æ“šçš„æ ¼å¼ (ç”¨æ–¼ t=0 çš„è¼¸å…¥)
        latest_row.rename(columns={p: f'{p}_value' for p in POLLUTANT_TARGETS}, inplace=True)
        
        return latest_row.reset_index(drop=True)

    except Exception as e:
        print(f"âŒ [OpenAQ] è™•ç†æ•¸æ“šå¤±æ•—: {e}")
        print("--- OpenAQ Traceback Start ---")
        traceback.print_exc()
        print("--- OpenAQ Traceback End ---")
        return pd.DataFrame()


# =================================================================
# Open-Meteo Weather Fetching Functions
# =================================================================

def fetch_weather_forecast(lat, lon, start_datetime):
    """
    å¾ Open-Meteo ç²å–æœªä¾† 24 å°æ™‚çš„å¤©æ°£é å ± (å¾æŒ‡å®šæ™‚é–“é–‹å§‹)ã€‚
    start_datetime é æœŸæ˜¯å¾ OpenAQ ä¾†çš„ timezone-naive Timestampã€‚
    """
    # ç¢ºä¿ start_datetime æ˜¯æœ‰æ•ˆçš„ Timestamp ç‰©ä»¶
    if start_datetime is None or pd.isna(start_datetime):
        print("âš ï¸ [OpenMeteo] ç„¡æ•ˆçš„é–‹å§‹æ™‚é–“æˆ³è¨˜ï¼Œç„¡æ³•ç²å–å¤©æ°£é å ±ã€‚")
        return pd.DataFrame()
        
    try:
        # Open-Meteo API åƒæ•¸
        params = {
            "latitude": lat,
            "longitude": lon,
            "hourly": ["temperature_2m", "relative_humidity_2m", "surface_pressure"],
            "timezone": "auto", # è®“ Open-Meteo è™•ç†æ™‚å€
            "forecast_hours": 48 # ç²å– 48 å°æ™‚é å ±
        }
        
        responses = openmeteo.weather_api(WEATHER_URL, params=params)
        
        # åƒ…ä½¿ç”¨ç¬¬ä¸€å€‹å›æ‡‰ (å¦‚æœæœ‰å¤šå€‹ç¶“ç·¯åº¦)
        response = responses[0]
        
        # ç²å–å°æ™‚æ•¸æ“š
        hourly = response.Hourly()
        
        hourly_data = {
            "datetime": pd.to_datetime(hourly.Time(), unit="s", utc=True), # ç¢ºä¿å®ƒæ˜¯ UTC
            "temperature": hourly.Variables(0).ValuesAsNumpy(),
            "humidity": hourly.Variables(1).ValuesAsNumpy(),
            "pressure": hourly.Variables(2).ValuesAsNumpy()
        }
        
        weather_df = pd.DataFrame(hourly_data)
        
        # 1. å°‡ UTC æ™‚é–“è½‰æ›ç‚ºæœ¬åœ°æ™‚å€ (å¸¶æ™‚å€è³‡è¨Š)
        weather_df['datetime'] = weather_df['datetime'].dt.tz_convert(LOCAL_TZ)
        
        # 2. ç§»é™¤æ™‚å€è³‡è¨Šï¼Œè®Šæˆ naive (åŒ¹é… OpenAQ æ•¸æ“šå’Œæ¨¡å‹è¨“ç·´)
        weather_df['datetime'] = weather_df['datetime'].dt.tz_localize(None)
        
        # 3. éæ¿¾å‡ºå¾é–‹å§‹æ™‚é–“ä¹‹å¾Œçš„æ•¸æ“š
        # start_datetime å·²ç¶“æ˜¯ naive Timestamp
        weather_df = weather_df[weather_df['datetime'] > start_datetime]
            
        # åƒ…ä¿ç•™æœªä¾† 24 å°æ™‚çš„é å ±
        weather_df = weather_df.sort_values(by='datetime').head(24).reset_index(drop=True)
        
        print(f"âœ… [OpenMeteo] Fetched {len(weather_df)} hours of weather forecast.")
        
        return weather_df
        
    except Exception as e:
        print(f"âŒ [OpenMeteo] å–å¾—å¤©æ°£é å ±å¤±æ•—: {e}")
        print("--- Weather Traceback Start ---")
        traceback.print_exc()
        print("--- Weather Traceback End ---")
        return pd.DataFrame()


# =================================================================
# Model Initialization and Feature Engineering
# =================================================================

def load_models():
    """è¼‰å…¥æ‰€æœ‰å·²å„²å­˜çš„ XGBoost æ¨¡å‹å’Œæ¨¡å‹å…ƒæ•¸æ“š"""
    global TRAINED_MODELS, LAST_OBSERVATION, FEATURE_COLUMNS, INITIAL_AQI_INFO
    
    # å³ä½¿æ¨¡å‹æª”æ¡ˆä¸å­˜åœ¨ï¼Œä¹Ÿå˜—è©¦è¼‰å…¥å…ƒæ•¸æ“š (Feature Columns/LAST_OBSERVATION)
    if os.path.exists(META_PATH):
        try:
            with open(META_PATH, 'r') as f:
                meta_data = json.load(f)
                FEATURE_COLUMNS = meta_data.get('feature_columns', [])
                
                # è¼‰å…¥ LAST_OBSERVATION
                last_obs_json = meta_data.get('last_observation')
                if last_obs_json:
                    last_obs_df = pd.DataFrame([last_obs_json])
                    # ç¢ºä¿ 'datetime' æ¬„ä½è¢«æ­£ç¢ºè½‰æ›
                    last_obs_df['datetime'] = pd.to_datetime(last_obs_df['datetime']).dt.tz_localize(None)
                    LAST_OBSERVATION = last_obs_df
                    print("âœ… [Model] LAST_OBSERVATION è¼‰å…¥æˆåŠŸã€‚")
                    
                INITIAL_AQI_INFO = meta_data.get('initial_aqi_info', {})
                
            # è¼‰å…¥æ¯å€‹ pollutant çš„æ¨¡å‹
            for param in POLLUTANT_TARGETS:
                model_path = os.path.join(MODELS_DIR, f'{param}_model.json')
                if os.path.exists(model_path):
                    xgb_model = xgb.XGBRegressor()
                    xgb_model.load_model(model_path)
                    TRAINED_MODELS[param] = xgb_model
                    print(f"âœ… [Model] {param} æ¨¡å‹è¼‰å…¥æˆåŠŸã€‚")
                else:
                    print(f"âš ï¸ [Model] æ‰¾ä¸åˆ° {param} æ¨¡å‹ ({model_path})ã€‚")
                    
        except Exception as e:
            print(f"ğŸš¨ [Model] è¼‰å…¥å…ƒæ•¸æ“šæˆ–æ¨¡å‹æ™‚ç™¼ç”ŸéŒ¯èª¤: {e}")
            
    if not TRAINED_MODELS:
        print("ğŸš¨ [Model] æœªè¼‰å…¥ä»»ä½•æ¨¡å‹ã€‚é æ¸¬åŠŸèƒ½å°‡ç„¡æ³•é‹ä½œã€‚")
        return False
    
    print(f"âœ… [Model] æ‰€æœ‰æ¨¡å‹å’Œå…ƒæ•¸æ“šè¼‰å…¥å®Œæˆã€‚ç¸½å…± {len(TRAINED_MODELS)} å€‹æ¨¡å‹ã€‚")
    return True

def create_datetime_features(df):
    """å‰µå»ºæ™‚é–“ç›¸é—œç‰¹å¾µï¼šå°æ™‚ã€æ˜ŸæœŸå¹¾ã€æœˆä»½"""
    df['hour'] = df['datetime'].dt.hour
    df['dayofweek'] = df['datetime'].dt.dayofweek
    df['month'] = df['datetime'].dt.month
    return df

def generate_lag_features(df, param):
    """ç‚ºå–®ä¸€æ±¡æŸ“ç‰©ç”Ÿæˆæ»¯å¾Œç‰¹å¾µ (lag features)"""
    for lag in [1, 2, 3, 6, 12, 24]:
        df[f'{param}_lag_{lag}h'] = df[f'{param}_value'].shift(lag)
    return df

def generate_rolling_features(df, param):
    """ç‚ºå–®ä¸€æ±¡æŸ“ç‰©ç”Ÿæˆæ»¾å‹•çµ±è¨ˆç‰¹å¾µ (rolling mean/std)"""
    for window in [6, 12, 24]:
        df[f'{param}_rolling_mean_{window}h'] = df[f'{param}_value'].rolling(window=window).mean()
        df[f'{param}_rolling_std_{window}h'] = df[f'{param}_value'].rolling(window=window).std()
    return df

def get_forecast_input_template(observation_for_prediction, weather_forecast_df):
    """
    å»ºç«‹æœªä¾† 24 å°æ™‚é æ¸¬çš„è¼¸å…¥æ¨¡æ¿ã€‚
    å®ƒåŒ…å« t=0 çš„å¯¦éš›è§€æ¸¬å€¼ï¼ˆå·²åœ¨ index() ä¸­ç”¨æœ€æ–°æ•¸æ“šè¦†è“‹ï¼‰ï¼Œä»¥åŠ t+1 åˆ° t+24 çš„æ™‚é–“å’Œå¤©æ°£é å ±ã€‚
    """
    
    # 1. å»ºç«‹ t+1 åˆ° t+24 çš„æ™‚é–“åºåˆ—
    start_dt = observation_for_prediction['datetime'].iloc[0]
    future_datetimes = [start_dt + timedelta(hours=i) for i in range(1, 25)]
    future_df = pd.DataFrame({'datetime': future_datetimes})
    
    # 2. åˆä½µå¤©æ°£é å ± (t+1 åˆ° t+24)
    #    ç”±æ–¼ weather_forecast_df å·²ç¶“è¢«éæ¿¾ç‚º t+1 åˆ° t+24ï¼Œå¯ä»¥ç›´æ¥åˆä½µ
    future_df = future_df.merge(weather_forecast_df, on='datetime', how='left')
    
    # 3. å»ºç«‹å®Œæ•´çš„é æ¸¬ DataFrame
    #    t=0 (å¯¦éš›è§€æ¸¬) + t+1 åˆ° t+24 (æœªä¾†é æ¸¬)
    full_prediction_df = pd.concat([observation_for_prediction, future_df], ignore_index=True)
    
    # 4. åˆå§‹åŒ–æ‰€æœ‰æ±¡æŸ“ç‰©ã€AQI æ¬„ä½ç‚º NaN (t+1 åˆ° t+24 çš„å€¼)
    for param in POLLUTANT_TARGETS:
        full_prediction_df[f'{param}_value'] = full_prediction_df.get(f'{param}_value', np.nan)
    full_prediction_df['aqi'] = full_prediction_df.get('aqi', np.nan)
    
    # 5. å‰µå»ºæ‰€æœ‰å¿…è¦çš„ç‰¹å¾µæ¬„ä½ï¼Œä¸¦å¡«å…¥ NaN
    for col in FEATURE_COLUMNS:
        if col not in full_prediction_df.columns:
            full_prediction_df[col] = np.nan
    
    # 6. å‰µå»ºæ™‚é–“ç‰¹å¾µ
    full_prediction_df = create_datetime_features(full_prediction_df)
    
    # ç¢ºä¿åªæœ‰éœ€è¦çš„ç‰¹å¾µæ¬„ä½
    return full_prediction_df


# =================================================================
# Main Prediction Logic
# =================================================================

def predict_future_multi(df, models, feature_cols):
    """
    åŸ·è¡Œéæ­¸å¤šæ­¥é æ¸¬ã€‚
    
    Args:
        df: åŒ…å« t=0 å¯¦éš›è§€æ¸¬å’Œ t+1 åˆ° t+24 å¤©æ°£é å ±çš„ DataFrameã€‚
        models: è¨“ç·´å¥½çš„æ¨¡å‹å­—å…¸ã€‚
        feature_cols: æ¨¡å‹éœ€è¦çš„ç‰¹å¾µåˆ—è¡¨ã€‚
        
    Returns:
        åŒ…å« t+1 åˆ° t+24 é æ¸¬çµæœçš„ DataFrameã€‚
    """
    N_STEPS = 24 # é æ¸¬æœªä¾† 24 å°æ™‚
    
    # å°‡æ‰€æœ‰æ•¸å€¼æ¬„ä½è½‰æ›ç‚º float
    for col in df.columns:
        if df[col].dtype == object and col != 'datetime':
            df[col] = pd.to_numeric(df[col], errors='coerce')
    
    # é€²è¡Œ 24 æ­¥éæ­¸é æ¸¬
    for t in range(1, N_STEPS + 1):
        
        # 1. ç²å–ç•¶å‰è¦é æ¸¬çš„æ™‚é–“é»çš„è¡Œ (å³ t æ™‚åˆ»)
        #    ç”±æ–¼ df æ˜¯ t=0 åˆ° t=24ï¼Œt=1 æ˜¯ç¬¬äºŒè¡Œ (index 1)
        current_idx = t
        
        if current_idx >= len(df):
            break

        # 2. æº–å‚™ç•¶å‰æ™‚é–“é» (t) çš„ç‰¹å¾µæ•¸æ“š
        # è¤‡è£½ t-1 çš„é æ¸¬/è§€æ¸¬å€¼åˆ° t æ™‚åˆ»çš„æ»¯å¾Œç‰¹å¾µ
        prev_idx = current_idx - 1
        
        for param in POLLUTANT_TARGETS:
            # å¡«å…… t æ™‚åˆ»çš„ 1-hour lag (ä½¿ç”¨ t-1 æ™‚åˆ»çš„ value)
            lag_1h_col = f'{param}_lag_{1}h'
            value_col = f'{param}_value'
            if lag_1h_col in df.columns and value_col in df.columns:
                 # ä½¿ç”¨ .loc é€²è¡Œç²¾ç¢ºè³¦å€¼
                 df.loc[current_idx, lag_1h_col] = df.loc[prev_idx, value_col]
                 
        # å¡«å…… t æ™‚åˆ»çš„ aqi lag 1h (ä½¿ç”¨ t-1 æ™‚åˆ»çš„ aqi)
        if 'aqi_lag_1h' in df.columns and 'aqi' in df.columns:
             df.loc[current_idx, 'aqi_lag_1h'] = df.loc[prev_idx, 'aqi']

        # ç²å–è¦å‚³å…¥æ¨¡å‹çš„ç‰¹å¾µ
        X_test = df.loc[current_idx, feature_cols].to_frame().T
        
        # 3. åŸ·è¡Œé æ¸¬
        current_predictions = {}
        for param, model in models.items():
            # åŸ·è¡Œé æ¸¬
            # ç¢ºä¿è¼¸å…¥ X_test ä¸å« NaN (XGBoost ä¸æ”¯æ´ NaN)
            X_test_filled = X_test.fillna(0) # âš ï¸ ç°¡åŒ–è™•ç†: åƒ…ç”¨ 0 å¡«å……ç¼ºå¤±å€¼ï¼Œé€™å¯èƒ½å½±éŸ¿æº–ç¢ºæ€§ï¼Œä½†é¿å…å´©æ½°
            
            pred_value = model.predict(X_test_filled)[0]
            current_predictions[param] = max(0, pred_value) # ç¢ºä¿æ¿ƒåº¦ä¸ç‚ºè² 
            
            # å°‡é æ¸¬å€¼å­˜å› DataFrame
            df.loc[current_idx, f'{param}_value'] = current_predictions[param]

        # 4. è¨ˆç®—ä¸¦å­˜å„² AQI é æ¸¬å€¼
        #    é¦–å…ˆè¨ˆç®— t æ™‚åˆ»çš„ç¸½é«” AQI
        df.loc[current_idx, 'aqi'] = calculate_aqi(df.loc[current_idx])
        
        # å°‡æœ€çµ‚çš„ AQI é æ¸¬å€¼å–®ç¨å„²å­˜ï¼Œä»¥ä¾¿åœ¨æœ€å¾Œè¿”å›æ™‚ä½¿ç”¨
        df.loc[current_idx, 'aqi_pred'] = df.loc[current_idx, 'aqi']
        
        
    # è¿”å› t=1 åˆ° t=24 çš„é æ¸¬çµæœ
    return df.iloc[1:].copy()


# =================================================================
# Flask Application Setup and Routes
# =================================================================

app = Flask(__name__)

# æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚è¼‰å…¥æ¨¡å‹å’Œæ¸¬ç«™åˆ—è¡¨
if not TRAINED_MODELS:
    print("â³ [App] æ­£åœ¨è¼‰å…¥æ¨¡å‹...")
    if load_models():
        print("âœ… [App] æ¨¡å‹è¼‰å…¥å®Œæˆã€‚")
        # è¼‰å…¥æ¸¬ç«™åˆ—è¡¨
        fetch_location_list()
    else:
        print("ğŸš¨ [App] ç„¡æ³•å•Ÿå‹•æ‡‰ç”¨ç¨‹å¼ï¼Œæ¨¡å‹è¼‰å…¥å¤±æ•—ã€‚")
        # å³ä½¿æ¨¡å‹è¼‰å…¥å¤±æ•—ï¼Œä»å˜—è©¦è¼‰å…¥æ¸¬ç«™åˆ—è¡¨ä»¥æä¾›åŸºæœ¬ä»‹é¢
        fetch_location_list()


@app.route('/', methods=['GET', 'POST'])
def index():
    """ä¸»é é¢ï¼šé¡¯ç¤ºæœ€æ–°è§€æ¸¬å’Œé æ¸¬çµæœ"""
    
    # ========== 1ï¸âƒ£ è™•ç†ç”¨æˆ¶è¼¸å…¥å’Œç‹€æ…‹è¨­å®š ==========
    global TARGET_LAT, TARGET_LON, DEFAULT_LOCATION_ID, DEFAULT_LOCATION_NAME
    
    selected_location_id = request.form.get('location_id') or request.args.get('location_id')
    
    if selected_location_id:
        # å˜—è©¦åœ¨ LOCATION_LIST ä¸­æ‰¾åˆ°å°æ‡‰çš„ç¶“ç·¯åº¦
        target_loc = next((loc for loc in LOCATION_LIST if str(loc['id']) == str(selected_location_id)), None)
        if target_loc:
            TARGET_LAT = target_loc['latitude']
            TARGET_LON = target_loc['longitude']
            DEFAULT_LOCATION_ID = target_loc['id']
            DEFAULT_LOCATION_NAME = target_loc['name']
        else:
            # å¦‚æœæ‰¾ä¸åˆ°ï¼Œå‰‡å›é€€åˆ°åˆå§‹çš„é è¨­å€¼ (é¿å…å‡ºéŒ¯)
            selected_location_id = DEFAULT_LOCATION_ID
            
    else:
         selected_location_id = DEFAULT_LOCATION_ID
         # ç¢ºä¿ç¶“ç·¯åº¦ä¹Ÿæ˜¯é è¨­çš„
         target_loc = next((loc for loc in LOCATION_LIST if str(loc['id']) == str(selected_location_id)), None)
         if target_loc:
             TARGET_LAT = target_loc['latitude']
             TARGET_LON = target_loc['longitude']

    print(f"ğŸŒ [Request] Selected Location: {DEFAULT_LOCATION_NAME} ({selected_location_id}) at ({TARGET_LAT}, {TARGET_LON})")
    
    
    # ========== 2ï¸âƒ£ ç²å–ç•¶å‰è§€æ¸¬æ•¸æ“š ==========
    current_observation_raw = fetch_latest_observation(selected_location_id)
    
    CURRENT_OBSERVATION_AQI = "N/A"
    CURRENT_OBSERVATION_TIME = "N/A"
    CURRENT_OBSERVATION_CATEGORY = "N/A"
    CURRENT_OBSERVATION_COLOR = "bg-gray-400"
    CURRENT_OBSERVATION_DT = None # ç”¨æ–¼å„²å­˜ Timestamp ç‰©ä»¶

    if not current_observation_raw.empty:
        latest_row = current_observation_raw.iloc[0]
        
        # --- Update AQI ---
        aqi_val = latest_row['aqi']
        CURRENT_OBSERVATION_AQI = int(aqi_val) if pd.notna(aqi_val) else "N/A"
        
        # --- Update Time (å’Œå„²å­˜ Timestamp ç‰©ä»¶) ---
        dt_val = latest_row['datetime']
        if pd.notna(dt_val):
            CURRENT_OBSERVATION_DT = dt_val 
            CURRENT_OBSERVATION_TIME = CURRENT_OBSERVATION_DT.strftime('%Y-%m-%d %H:%M')

        # --- Update Category and Color ---
        if CURRENT_OBSERVATION_AQI != "N/A":
             CURRENT_OBSERVATION_CATEGORY, CURRENT_OBSERVATION_COLOR = get_aqi_category(CURRENT_OBSERVATION_AQI)
        
        print(f"âœ… [Observation] Latest AQI: {CURRENT_OBSERVATION_AQI} at {CURRENT_OBSERVATION_TIME}")
    else:
        print(f"âš ï¸ [Observation] OpenAQ returned empty data for location {selected_location_id}. Continuing in fallback mode.")


    # ========== 3ï¸âƒ£ ç²å–æœªä¾†å¤©æ°£é å ± (ä½¿ç”¨ Timestamp ç‰©ä»¶) ==========
    weather_forecast_df = pd.DataFrame()
    if CURRENT_OBSERVATION_DT is not None: 
        # å¾ç•¶å‰è§€æ¸¬æ™‚é–“é–‹å§‹ï¼Œç²å–æœªä¾† 24 å°æ™‚çš„å¤©æ°£é å ± (ç”¨æ–¼ t+1 åˆ° t+24)
        weather_forecast_df = fetch_weather_forecast(
            TARGET_LAT, 
            TARGET_LON, 
            CURRENT_OBSERVATION_DT # ç›´æ¥å‚³é Timestamp ç‰©ä»¶
        )
    else:
        print("âš ï¸ [Weather] Skipping weather fetch because CURRENT_OBSERVATION_DT is None.")
    
    
    # ========== 4ï¸âƒ£ æª¢æŸ¥æ¨¡å‹å’Œæ•¸æ“šå®Œæ•´æ€§ ==========
    aqi_predictions = []
    
    # æ¨¡å‹å¿…é ˆå­˜åœ¨ã€LAST_OBSERVATION å¿…é ˆè¼‰å…¥ã€å¤©æ°£é å ±å¿…é ˆæœ‰ 24 ç­†æ•¸æ“š
    is_valid_for_prediction = bool(TRAINED_MODELS) and \
                             LAST_OBSERVATION is not None and \
                             not LAST_OBSERVATION.empty and \
                             weather_forecast_df.shape[0] == 24
    
    is_fallback_mode = True

    # ========== 5ï¸âƒ£ å»ºç«‹é æ¸¬æˆ–å›é€€é¡¯ç¤º ==========
    
    if is_valid_for_prediction and not current_observation_raw.empty:
        try:
            # 1. ä»¥è¨“ç·´æ™‚çš„ LAST_OBSERVATION ä½œç‚ºæ¨¡æ¿ï¼Œä¿ç•™å…¶æ‰€æœ‰æ­·å²/æ»¯å¾Œç‰¹å¾µ
            observation_for_prediction = LAST_OBSERVATION.iloc[:1].copy()
            
            latest_row = current_observation_raw.iloc[0]
            dt_val = CURRENT_OBSERVATION_DT # ä½¿ç”¨æˆ‘å€‘å·²ç¶“é©—è­‰éçš„ Timestamp
                
            # 2. æ ¸å¿ƒä¿®æ­£: å°‡ç•¶å‰è§€æ¸¬çš„æ™‚é–“è¨­ç½®ç‚ºèµ·å§‹æ™‚é–“ (t=0)
            observation_for_prediction['datetime'] = dt_val

            # 3. æ ¸å¿ƒä¿®æ­£: ç”¨ç•¶å‰æ¸¬ç«™çš„è§€æ¸¬å€¼è¦†è“‹è¨“ç·´æ™‚å„²å­˜çš„ "æœ€æ–°è§€æ¸¬å€¼" (t=0)
            for col in POLLUTANT_TARGETS:
                col_to_match = f'{col}_value'
                if col_to_match in observation_for_prediction.columns:
                     observation_for_prediction[col_to_match] = latest_row.get(col_to_match, np.nan)
            
            if 'aqi' in observation_for_prediction.columns:
                observation_for_prediction['aqi'] = latest_row.get('aqi', np.nan)

            # 4. é€²è¡Œé¡å¤–æª¢æŸ¥ï¼šç”¨æœ€æ–°çš„è§€æ¸¬å€¼ä¾†æ›´æ–° t-1 çš„ LAG_1h ç‰¹å¾µ
            for param in POLLUTANT_TARGETS:
                 value_col = f'{param}_value'
                 lag_1h_col = f'{param}_lag_1h'
                 if value_col in observation_for_prediction.columns and lag_1h_col in observation_for_prediction.columns:
                     # ä½¿ç”¨ç•¶å‰æœ€æ–°è§€æ¸¬å€¼ä½œç‚º t-1 çš„è¼¸å…¥
                     observation_for_prediction[lag_1h_col] = observation_for_prediction[value_col].iloc[0]

            aqi_lag_1h_col = 'aqi_lag_1h'
            if 'aqi' in observation_for_prediction.columns and aqi_lag_1h_col in observation_for_prediction.columns:
                 # ä½¿ç”¨ç•¶å‰æœ€æ–° AQI ä½œç‚º t-1 çš„è¼¸å…¥
                 observation_for_prediction[aqi_lag_1h_col] = observation_for_prediction['aqi'].iloc[0]


            # 5. åŸ·è¡Œé æ¸¬
            # å»ºç«‹ t=0 åˆ° t=24 çš„å®Œæ•´è¼¸å…¥æ¨¡æ¿
            full_input_df = get_forecast_input_template(observation_for_prediction, weather_forecast_df)
            
            # åŸ·è¡Œéæ­¸é æ¸¬
            predictions_df = predict_future_multi(full_input_df, TRAINED_MODELS, FEATURE_COLUMNS)
            
            # æº–å‚™è¼¸å‡ºæ ¼å¼
            predictions_df['datetime_local'] = predictions_df['datetime'].dt.tz_localize(LOCAL_TZ)
            predictions_df = predictions_df.loc[:, ['datetime_local', 'aqi_pred']].copy()
            
            # è¨ˆç®—æœ€å¤§é æ¸¬ AQI
            max_aqi_val = predictions_df['aqi_pred'].max()
            max_aqi = int(max_aqi_val) if pd.notna(max_aqi_val) and max_aqi_val > 0 else CURRENT_OBSERVATION_AQI
            
            predictions_df['aqi'] = predictions_df['aqi_pred'].apply(
                lambda x: int(x) if pd.notna(x) else "N/A"
            ).astype(object)
            
            aqi_predictions = [
                {'time': item['datetime_local'].strftime('%Y-%m-%d %H:%M'), 'aqi': item['aqi']}
                for item in predictions_df.to_dict(orient='records')
            ]
            if aqi_predictions:
                is_fallback_mode = False
                print("âœ… [Request] Prediction successful!")
        except Exception as e:
            print(f"âŒ [Predict] Error during prediction logic: {e}")
            print("--- Prediction Traceback Start ---")
            traceback.print_exc()
            print("--- Prediction Traceback End ---")

    if is_fallback_mode:
        print("ğŸš¨ [Fallback Mode] Showing latest observed AQI only.")
        # å¦‚æœç•¶å‰æœ‰è§€æ¸¬å€¼ï¼Œå‰‡åªé¡¯ç¤ºè§€æ¸¬å€¼
        if CURRENT_OBSERVATION_AQI != "N/A":
            aqi_predictions = [{
                'time': CURRENT_OBSERVATION_TIME,
                'aqi': CURRENT_OBSERVATION_AQI,
                'is_obs': True
            }]

    # ========== 6ï¸âƒ£ è¼¸å‡ºé é¢ =========
    return render_template(
        'index.html',
        max_aqi=max_aqi,
        current_aqi=CURRENT_OBSERVATION_AQI,
        current_time=CURRENT_OBSERVATION_TIME,
        current_category=CURRENT_OBSERVATION_CATEGORY,
        current_color=CURRENT_OBSERVATION_COLOR,
        selected_location_id=str(DEFAULT_LOCATION_ID), # ç¢ºä¿ç‚ºå­—ä¸²
        selected_location_name=DEFAULT_LOCATION_NAME,
        location_list=LOCATION_LIST,
        aqi_predictions=aqi_predictions,
        is_fallback_mode=is_fallback_mode,
    )

if __name__ == '__main__':
    # Flask æ‡‰ç”¨ç¨‹å¼æœƒåœ¨ä¼ºæœå™¨ä¸­é‹è¡Œ
    # app.run(debug=True)
    pass
