# app.py - ä¾› Render éƒ¨ç½²ä½¿ç”¨ (å·²ç§»é™¤è€—æ™‚çš„è¨“ç·´é‚è¼¯)

# =================================================================
# å°å…¥æ‰€æœ‰å¿…è¦çš„åº«
# =================================================================
import requests
import pandas as pd
import datetime
import random
import re
import os
import warnings
import numpy as np
import xgboost as xgb
import json # æ–°å¢ï¼šç”¨æ–¼è®€å–å…ƒæ•¸æ“š
import io # æ–°å¢ï¼šç”¨æ–¼è®€å– JSON å­—ä¸²ç‚º DataFrame
from datetime import timedelta, timezone
from flask import Flask, render_template

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# æ¨¡å‹èˆ‡å…ƒæ•¸æ“šè·¯å¾‘
MODELS_DIR = 'models'
META_PATH = os.path.join(MODELS_DIR, 'model_meta.json')

# =================================================================
# å…¨åŸŸè®Šæ•¸ - æ”¹ç‚ºå¾æª”æ¡ˆè¼‰å…¥
# =================================================================
TRAINED_MODELS = {}
LAST_OBSERVATION = None
FEATURE_COLUMNS = []
POLLUTANT_PARAMS = [] # å¯¦éš›æ‰¾åˆ°ä¸¦è¨“ç·´çš„æ¨¡å‹åƒæ•¸
HOURS_TO_PREDICT = 24

# =================================================================
# å¸¸æ•¸è¨­å®š (åƒ…ä¿ç•™èˆ‡é æ¸¬ç›¸é—œçš„å¸¸æ•¸)
# =================================================================
LOCAL_TZ = "Asia/Taipei"
LAG_HOURS = [1, 2, 3, 6, 12, 24] # é æ¸¬éè¿´éœ€è¦é€™äº›åƒæ•¸
ROLLING_WINDOWS = [6, 12, 24] # é æ¸¬éè¿´éœ€è¦é€™äº›åƒæ•¸
POLLUTANT_TARGETS = ["pm25", "pm10", "o3", "no2", "so2", "co"] # ç”¨æ–¼ AQI è¨ˆç®—

# ç°¡åŒ–çš„ AQI åˆ†ç´šè¡¨ (å·²å¾¹åº•æ¸…ç† U+00A0 éš±è—å­—å…ƒ)
AQI_BREAKPOINTS = {
    "pm25": [(0.0, 12.0, 0, 50), (12.1, 35.4, 51, 100), (35.5, 55.4, 101, 150), (55.5, 150.4, 151, 200)],
    "pm10": [(0, 54, 0, 50), (55, 154, 51, 100), (155, 254, 101, 150), (255, 354, 151, 200)],
    "o3": [(0, 54, 0, 50), (55, 70, 51, 100), (71, 85, 101, 150), (86, 105, 151, 200)],
    "co": [(0.0, 4.4, 0, 50), (4.5, 9.4, 51, 100), (9.5, 12.4, 101, 150), (12.5, 15.4, 151, 200)],
    "no2": [(0, 100, 0, 50), (101, 360, 51, 100), (361, 649, 101, 150), (650, 1249, 151, 200)],
    "so2": [(0, 35, 0, 50), (36, 75, 51, 100), (76, 185, 101, 150), (186, 304, 151, 200)],
}

# =================================================================
# è¼”åŠ©å‡½å¼: AQI è¨ˆç®—
# =================================================================

def calculate_aqi_sub_index(param: str, concentration: float) -> float:
    """è¨ˆç®—å–®ä¸€æ±¡æŸ“ç‰©æ¿ƒåº¦å°æ‡‰çš„ AQI å­æŒ‡æ•¸ (I)"""
    if pd.isna(concentration) or concentration < 0:
        return 0

    breakpoints = AQI_BREAKPOINTS.get(param)
    if not breakpoints:
        return 0

    for C_low, C_high, I_low, I_high in breakpoints:
        if C_low <= concentration <= C_high:
            if C_high == C_low:
                return I_high
            I = ((I_high - I_low) / (C_high - C_low)) * (concentration - C_low) + I_low
            return np.round(I)

        if concentration > breakpoints[-1][1]:
            I_low, I_high = breakpoints[-1][2], breakpoints[-1][3]
            C_low, C_high = breakpoints[-1][0], breakpoints[-1][1]
            if C_high == C_low:
                return I_high
            I_rate = (I_high - I_low) / (C_high - C_low)
            I = I_high + I_rate * (concentration - C_high)
            return np.round(I)

    return 0

def calculate_aqi(row: pd.Series, params: list) -> int:
    """æ ¹æ“šå¤šå€‹æ±¡æŸ“ç‰©æ¿ƒåº¦è¨ˆç®—æœ€çµ‚ AQI (å–æœ€å¤§å­æŒ‡æ•¸)"""
    sub_indices = []
    for p in params:
        col_name = f'{p}_pred' if f'{p}_pred' in row else f'{p}_value'
        if col_name in row and not pd.isna(row[col_name]):
            sub_index = calculate_aqi_sub_index(p, row[col_name])
            sub_indices.append(sub_index)

    if not sub_indices:
        return np.nan

    return int(np.max(sub_indices))

# =================================================================
# é æ¸¬å‡½å¼
# =================================================================

def predict_future_multi(models, last_data, feature_cols, pollutant_params, hours=24):
    """é æ¸¬æœªä¾† N å°æ™‚çš„å¤šå€‹ç›®æ¨™æ±¡æŸ“ç‰© (éè¿´é æ¸¬) ä¸¦è¨ˆç®— AQI"""
    predictions = []

    # last_data ç¾åœ¨æ˜¯å–®è¡Œ DataFrameï¼Œéœ€è¦å…ˆè½‰æ›æ™‚é–“æ ¼å¼
    last_data['datetime'] = pd.to_datetime(last_data['datetime']).dt.tz_localize('UTC')
    last_datetime_aware = last_data['datetime'].iloc[0]
    # æ³¨æ„ï¼šé€™è£¡ä½¿ç”¨ to_dict() å‰µå»ºä¸€å€‹å¯è®Šå­—å…¸å‰¯æœ¬ä½œç‚ºè¿­ä»£çš„åŸºç¤
    current_data_dict = last_data[feature_cols].iloc[0].to_dict()

    weather_feature_names_base = ['temperature', 'humidity', 'pressure']
    weather_feature_names = [col for col in weather_feature_names_base if col in feature_cols]
    has_weather = bool(weather_feature_names)

    for h in range(hours):
        future_time = last_datetime_aware + timedelta(hours=h + 1)
        pred_features = current_data_dict.copy()

        # 1. æ›´æ–°æ™‚é–“ç‰¹å¾µ
        pred_features['hour'] = future_time.hour
        pred_features['day_of_week'] = future_time.dayofweek
        pred_features['month'] = future_time.month
        pred_features['day_of_year'] = future_time.timetuple().tm_yday # ä½¿ç”¨ day_of_year
        pred_features['is_weekend'] = int(future_time.dayofweek in [5, 6])
        pred_features['hour_sin'] = np.sin(2 * np.pi * future_time.hour / 24)
        pred_features['hour_cos'] = np.cos(2 * np.pi * future_time.hour / 24)
        pred_features['day_sin'] = np.sin(2 * np.pi * pred_features['day_of_year'] / 365)
        pred_features['day_cos'] = np.cos(2 * np.pi * pred_features['day_of_year'] / 365)

        # 2. æ¨¡æ“¬æœªä¾†å¤©æ°£è®ŠåŒ– (ä½¿ç”¨å‰ä¸€å°æ™‚çš„å¤©æ°£å€¼é€²è¡Œéš¨æ©Ÿæ“¾å‹•)
        if has_weather:
            np.random.seed(future_time.hour + future_time.day + 42)
            for w_col in weather_feature_names:
                base_value = current_data_dict.get(w_col)
                if base_value is not None and not np.isnan(base_value):
                    # æ¨¡æ“¬è¼•å¾®éš¨æ©Ÿè®ŠåŒ–
                    new_weather_value = base_value + np.random.normal(0, 0.5)
                    pred_features[w_col] = new_weather_value
                    # å°‡æ–°çš„å¤©æ°£å€¼æ›´æ–°åˆ° current_data_dictï¼Œä»¥ä¾¿ä¸‹ä¸€å°æ™‚ä½¿ç”¨
                    current_data_dict[w_col] = new_weather_value

        current_prediction_row = {'datetime': future_time}
        new_pollutant_values = {}

        # 3. é æ¸¬æ‰€æœ‰æ±¡æŸ“ç‰©
        for param in pollutant_params:
            model = models[param]
            # ç¢ºä¿è¼¸å…¥ç‰¹å¾µçš„é †åºèˆ‡æ¨¡å‹è¨“ç·´æ™‚ä¸€è‡´
            pred_input_data = {col: pred_features.get(col, 0) for col in feature_cols}
            pred_input = np.array([pred_input_data[col] for col in feature_cols]).reshape(1, -1)
            pred = model.predict(pred_input)[0]
            pred = max(0, pred) # æ¿ƒåº¦ä¸èƒ½å°æ–¼ 0

            current_prediction_row[f'{param}_pred'] = pred
            new_pollutant_values[param] = pred

        # 4. è¨ˆç®—é æ¸¬çš„ AQI
        predicted_aqi = calculate_aqi(pd.Series(current_prediction_row), pollutant_params)
        current_prediction_row['aqi_pred'] = predicted_aqi
        new_pollutant_values['aqi'] = predicted_aqi

        predictions.append(current_prediction_row)

        # 5. æ›´æ–°æ»¯å¾Œç‰¹å¾µ (ç”¨ç•¶å‰é æ¸¬å€¼å¡«å…… Lag_1hï¼Œä¸¦å°‡å…¶ä»– Lag å‘å¾Œç§»å‹•)
        for param in pollutant_params + ['aqi']:
            # å¾æœ€å¤§çš„ Lag é–‹å§‹æ›´æ–°ï¼Œé¿å…è¦†è“‹
            for i in range(len(LAG_HOURS) - 1, 0, -1):
                lag_current = LAG_HOURS[i]
                lag_prev = LAG_HOURS[i-1]
                lag_current_col = f'{param}_lag_{lag_current}h'
                lag_prev_col = f'{param}_lag_{lag_prev}h'

                if lag_current_col in current_data_dict and lag_prev_col in current_data_dict:
                    current_data_dict[lag_current_col] = current_data_dict[lag_prev_col]

            # æ›´æ–° 1 å°æ™‚æ»¯å¾Œç‰¹å¾µç‚ºç•¶å‰é æ¸¬å€¼
            if f'{param}_lag_1h' in current_data_dict and param in new_pollutant_values:
                current_data_dict[f'{param}_lag_1h'] = new_pollutant_values[param]

        # 6. æ»¾å‹•å¹³å‡/æ¨™æº–å·®ç‰¹å¾µç„¡æ³•åœ¨éè¿´ä¸­æº–ç¢ºæ›´æ–°ï¼Œé€™è£¡ä¿æŒçœç•¥


    return pd.DataFrame(predictions)


# =================================================================
# æ¨¡å‹è¼‰å…¥é‚è¼¯
# =================================================================

def load_models_and_metadata():
    global TRAINED_MODELS, LAST_OBSERVATION, FEATURE_COLUMNS, POLLUTANT_PARAMS

    if not os.path.exists(META_PATH):
        print("ğŸš¨ [Load] æ‰¾ä¸åˆ°æ¨¡å‹å…ƒæ•¸æ“šæª”æ¡ˆ (model_meta.json)ï¼Œç„¡æ³•è¼‰å…¥æ¨¡å‹ã€‚")
        return

    try:
        # 1. è¼‰å…¥å…ƒæ•¸æ“š
        with open(META_PATH, 'r', encoding='utf-8') as f:
            metadata = json.load(f)

        POLLUTANT_PARAMS = metadata.get('pollutant_params', [])
        FEATURE_COLUMNS = metadata.get('feature_columns', [])

        # å°‡æœ€å¾Œä¸€ç­†æ•¸æ“šçš„ JSON è½‰æ›å› DataFrame
        if 'last_observation_json' in metadata:
            # ä½¿ç”¨ StringIO æ¨¡æ“¬æª”æ¡ˆè®€å–ï¼Œç¢ºä¿æ ¼å¼æ­£ç¢º
            LAST_OBSERVATION = pd.read_json(io.StringIO(metadata['last_observation_json']), orient='records')

        # 2. è¼‰å…¥ XGBoost æ¨¡å‹
        TRAINED_MODELS = {}
        params_to_check = list(POLLUTANT_PARAMS)

        for param in params_to_check:
            model_path = os.path.join(MODELS_DIR, f'{param}_model.json')
            if os.path.exists(model_path):
                model = xgb.XGBRegressor()
                model.load_model(model_path)
                TRAINED_MODELS[param] = model
            else:
                print(f"âŒ [Load] æ‰¾ä¸åˆ° {param} çš„æ¨¡å‹æª”æ¡ˆ: {model_path}")

        # æœ€çµ‚æ›´æ–° POLLUTANT_PARAMSï¼Œåªä¿ç•™æˆåŠŸè¼‰å…¥æ¨¡å‹çš„
        POLLUTANT_PARAMS = list(TRAINED_MODELS.keys())

        if TRAINED_MODELS:
            print(f"âœ… [Load] æˆåŠŸè¼‰å…¥ {len(TRAINED_MODELS)} å€‹æ¨¡å‹ã€‚")
        else:
            print("ğŸš¨ [Load] æœªè¼‰å…¥ä»»ä½•æ¨¡å‹ã€‚")


    except Exception as e:
        print(f"âŒ [Load] æ¨¡å‹è¼‰å…¥å¤±æ•—: {e}")
        TRAINED_MODELS = {}
        LAST_OBSERVATION = None
        FEATURE_COLUMNS = []
        POLLUTANT_PARAMS = []

# =================================================================
# Flask æ‡‰ç”¨ç¨‹å¼è¨­å®šèˆ‡å•Ÿå‹•
# =================================================================
app = Flask(__name__)

# æ‡‰ç”¨ç¨‹å¼å•Ÿå‹•æ™‚ï¼Œç«‹å³åŸ·è¡Œæ¨¡å‹è¼‰å…¥ (å¿«é€Ÿ)
with app.app_context():
    load_models_and_metadata()

@app.route('/')
def index():
    city_name = "é«˜é›„"

    # æª¢æŸ¥æ¨¡å‹æ˜¯å¦æˆåŠŸè¼‰å…¥
    if TRAINED_MODELS and LAST_OBSERVATION is not None and not LAST_OBSERVATION.empty:
        try:
            # åƒ…åŸ·è¡Œå¿«é€Ÿçš„é æ¸¬é‚è¼¯ (predict_future_multi)
            future_predictions = predict_future_multi(
                TRAINED_MODELS,
                LAST_OBSERVATION.copy(), # å‚³éå‰¯æœ¬ï¼Œé¿å…ä¿®æ”¹å…¨åŸŸè®Šæ•¸
                FEATURE_COLUMNS,
                POLLUTANT_PARAMS,
                hours=HOURS_TO_PREDICT
            )

            # æ ¼å¼åŒ–çµæœ
            future_predictions['datetime_local'] = future_predictions['datetime'].dt.tz_convert(LOCAL_TZ)

            # ç¢ºä¿ aqi_pred æ˜¯æ•¸å­—å†å– max
            if not future_predictions.empty and future_predictions['aqi_pred'].dtype in [np.int64, np.float64]:
                 max_aqi = int(future_predictions['aqi_pred'].max())
            else:
                 max_aqi = "N/A"

            aqi_predictions = [
                {'time': item['datetime_local'].strftime('%Y-%m-%d %H:%M'), 'aqi': int(item['aqi_pred'])}
                for item in future_predictions.to_dict(orient='records')
            ]

        except Exception as e:
            max_aqi = "N/A"
            aqi_predictions = []
            print(f"âŒ [Request] é æ¸¬åŸ·è¡Œå¤±æ•—: {e}")

    else:
        max_aqi = "N/A"
        aqi_predictions = []
        print("ğŸš¨ [Request] æ¨¡å‹æˆ–æ•¸æ“šå°šæœªåˆå§‹åŒ–ï¼Œç„¡æ³•é€²è¡Œé æ¸¬ã€‚")

    return render_template('index.html', max_aqi=max_aqi, aqi_predictions=aqi_predictions, city_name=city_name)

if __name__ == '__main__':
    # åœ¨æœ¬åœ°ç’°å¢ƒé‹è¡Œæ™‚ä½¿ç”¨
    app.run(debug=True)
